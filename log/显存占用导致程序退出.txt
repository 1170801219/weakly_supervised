----------------分析------------------------------------
1. 反向传播之后显存占用明显增大
2. 清除catch之后显存占用没有减小太多

------------------控制台输出----------------------------
C:\Users\24210\Anaconda3\envs\tensorflow\python.exe G:/my_code/python/weakly_superivsed/experimental_code/vgg19_voc2012/vgg19_on_voc2012.py
使用计算平台 cuda:0
batch size: 1
第 0 个batch
开始计算，清除catch之后的显存占用 575143936
读取一个batch_img,显存占用 577241088
读取一个batch_label,显存占用 577241600
前向传播,显存占用 658499584
计算loss,显存占用 658501120
loss:  2.9770658016204834
反向传播,显存占用 1153186304
更新参数,显存占用 1153186304
第 1 个batch
开始计算，清除catch之后的显存占用 1151088640
读取一个batch_img,显存占用 1152464896
读取一个batch_label,显存占用 1152465408
前向传播,显存占用 1233775104
计算loss,显存占用 1233776128
loss:  3.0021321773529053
Traceback (most recent call last):
  File "G:/my_code/python/weakly_superivsed/experimental_code/vgg19_voc2012/vgg19_on_voc2012.py", line 74, in <module>
    loss.backward()
  File "C:\Users\24210\Anaconda3\envs\tensorflow\lib\site-packages\torch\tensor.py", line 107, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "C:\Users\24210\Anaconda3\envs\tensorflow\lib\site-packages\torch\autograd\__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 2.00 GiB total capacity; 1.15 GiB already allocated; 77.39 MiB free; 5.35 MiB cached)

Process finished with exit code 1
